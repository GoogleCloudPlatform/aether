module TestTokenizerLoader;

// IO
@extern(library="aether_runtime", symbol="write_file_safe")
func write_file_safe(path: String, content: String, append: Bool) -> Bool;

@extern(library="aether_runtime", symbol="read_file_safe")
func read_file_safe(path: String, max_size: Int) -> String;

@extern(library="aether_runtime", symbol="aether_print")
func aether_print(s: String) -> Void;

func println(s: String) -> Void {
    aether_print(s);
    aether_print("\n");
}

// JSON
type JsonValue = String;

@extern(library="aether_runtime", symbol="parse_json")
func parse_json(json_string: String) -> JsonValue;

@extern(library="aether_runtime", symbol="json_get_field")
func json_get_field(json_value: JsonValue, field_name: String) -> JsonValue;

@extern(library="aether_runtime", symbol="to_integer")
func to_integer(json_value: JsonValue) -> Int;

// Strings
@extern(library="aether_runtime", symbol="string_length")
func string_length(s: String) -> Int;

@extern(library="aether_runtime", symbol="int_to_string")
func int_to_string(i: Int) -> String;

@extern(library="aether_runtime", symbol="string_split")
func string_split(s: String, delimiter: String) -> Array<String>;

@extern(library="aether_runtime", symbol="aether_strdup")
func aether_strdup(s: String) -> String;

func main() -> Int {
    let vocab_content = "{\"foo\": 1, \"bar\": 2, \"<unk>\": 0}";
    let merges_content = "f o o\nb a r";
    
    // Write test files
    let write_vocab = write_file_safe("vocab_test.json", vocab_content, false);
    if (write_vocab) {
        println("Vocab write success");
    } else {
        println("Failed to write vocab file");
        return 1;
    }
    
    let write_merges = write_file_safe("merges_test.txt", merges_content, false);
    if (write_merges) {
        println("Merges write success");
    } else {
        println("Failed to write merges file");
        return 1;
    }
    
    // Test loading vocab
    let read_vocab = read_file_safe("vocab_test.json", 1024);
    if (string_length(read_vocab) == 0) {
        println("Failed to read vocab file");
        return 1;
    }
    println("Vocab read success");
    
    let vocab_json = parse_json(read_vocab);
    println("Called parse_json");
    
    let len = string_length(vocab_json);
    aether_print("Length: ");
    println(int_to_string(len));
    
    if (len == 0) {
        println("Failed to parse vocab JSON");
        return 1;
    }
    println("Vocab parse success");
    println("JSON Content:");
    println(vocab_json);
    
    println("Cloning vocab...");
    let cloned = aether_strdup(vocab_json);
    println("Cloned.");
    
    println("Getting foo...");
    let foo_val = json_get_field(cloned, "foo");
    println("Got foo val:");
    println(foo_val);
    
    let foo_id = to_integer(foo_val);
    println("Foo ID:");
    println(int_to_string(foo_id));
    
    if (foo_id != 1) {
        aether_print("Incorrect foo id: ");
        println(int_to_string(foo_id));
        return 1;
    }
    
    let unk_val = json_get_field(vocab_json, "<unk>");
    let unk_id = to_integer(unk_val);
    
    if (unk_id != 0) {
        aether_print("Incorrect unk id: ");
        println(int_to_string(unk_id));
        return 1;
    }
    
    // Test loading merges
    let read_merges = read_file_safe("merges_test.txt", 1024);
    let lines = string_split(read_merges, "\n");
    
    println("Tokenizer loader test passed");
    return 0;
}
